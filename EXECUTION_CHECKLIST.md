# âœ… SAFER v3.0: Quick Execution Checklist

**Purpose:** Step-by-step guide to run the complete project  
**Time Required:** ~90 minutes (including training)  
**Prerequisites:** Python 3.8+, ~4GB RAM, C-MAPSS data

---

## ðŸš€ 5-MINUTE SETUP

```bash
# 1. Navigate to project
cd /path/to/SAFER\ v3.0\ -\ Initial

# 2. Install dependencies
pip install -r requirements.txt

# 3. Verify setup
python -c "import torch, numpy as np; print('âœ“ Ready')"

# 4. Check data exists
ls CMAPSSData/train_FD001.txt
ls CMAPSSData/test_FD001.txt
ls CMAPSSData/RUL_FD001.txt
```

---

## ðŸ“‹ EXECUTION PHASES (90 minutes total)

### PHASE 1: Data Preparation (5 min)
```bash
# What: Load and preprocess C-MAPSS dataset
# Time: 5 minutes
# Status: âœ“ Ready

python << 'EOF'
import numpy as np
from pathlib import Path
from safer_v3.utils.dataset import load_cmapss, prepare_sequences

print("Loading C-MAPSS FD001...")
data_dir = Path('CMAPSSData')
X_train, y_train, X_test, y_test = load_cmapss(
    data_dir=data_dir,
    dataset='FD001',
    normalize=True,
    sequence_length=30,
)

print(f"âœ“ Training: {X_train.shape}")
print(f"âœ“ Testing: {X_test.shape}")

# Prepare sequences
X_train_seq, y_train_seq = prepare_sequences(X_train, y_train, seq_len=30)
X_test_seq, y_test_seq = prepare_sequences(X_test, y_test, seq_len=30)

print(f"âœ“ Sequences prepared: {X_train_seq.shape}")

# Save
Path('outputs').mkdir(exist_ok=True)
np.save('outputs/X_train_seq.npy', X_train_seq)
np.save('outputs/y_train_seq.npy', y_train_seq)
np.save('outputs/X_test_seq.npy', X_test_seq)
np.save('outputs/y_test_seq.npy', y_test_seq)

print("âœ“ Data saved")
EOF

# Expected Output:
# âœ“ Training: (13096, 14)
# âœ“ Testing: (10196, 14)
# âœ“ Sequences prepared: (13067, 30, 14)
# âœ“ Data saved
```

### PHASE 2a: Train Mamba (15 min)
```bash
# What: Train Mamba RUL predictor (DAL E)
# Time: 15 minutes
# Status: âœ“ Ready

python scripts/train_baseline_fd001.py --model mamba --epochs 20

# Expected Output:
# âœ“ Mamba model created
# Epoch 5/20: Loss = 0.0234
# Epoch 10/20: Loss = 0.0156
# Epoch 15/20: Loss = 0.0089
# Epoch 20/20: Loss = 0.0045
# âœ“ Test RMSE: 20.40 cycles
# âœ“ Model saved: checkpoints/mamba_rul.pt
```

### PHASE 2b: Train LPV-SINDy (10 min)
```bash
# What: Train LPV-SINDy physics monitor (DAL C)
# Time: 10 minutes
# Status: âœ“ Ready

python scripts/train_physics_fd001.py

# Expected Output:
# âœ“ Training LPV-SINDy...
# âœ“ Fit complete: 1673 non-zero terms
# âœ“ Sparsity: 42.1%
# âœ“ Train RMSE: 0.79
# âœ“ Scheduling parameter: [0.342, 0.987]
# âœ“ LPV Decomposition: Îžâ‚ norm = 0.089
# âœ“ Model saved: checkpoints/lpv_sindy_model.pt
```

### PHASE 2c: Train LSTM Baseline (15 min)
```bash
# What: Train LSTM safety fallback (DAL C)
# Time: 15 minutes
# Status: âœ“ Ready

python scripts/train_baseline_fd001.py --model lstm --epochs 20

# Expected Output:
# âœ“ LSTM model created
# Epoch 5/20: Loss = 0.0312
# Epoch 10/20: Loss = 0.0198
# Epoch 15/20: Loss = 0.0124
# Epoch 20/20: Loss = 0.0067
# âœ“ Test RMSE: 38.24 cycles
# âœ“ Model saved: checkpoints/lstm_baseline.pt
```

### PHASE 3: Conformal Calibration (5 min)
```bash
# What: Calibrate prediction intervals
# Time: 5 minutes
# Status: âœ“ Ready

python scripts/calibrate_fd001.py

# Expected Output:
# âœ“ Conformal predictor calibrated
# âœ“ Calibration samples: 5098
# âœ“ Coverage achieved: 91.2%
# âœ“ Avg interval width: 38.55 cycles
# âœ“ Saved: checkpoints/conformal_params.json
```

### PHASE 4: Run Simplex (5 min)
```bash
# What: Test mode switching logic
# Time: 5 minutes
# Status: âœ“ Ready

python scripts/alert_and_simplex_fd001.py

# Expected Output:
# âœ“ Simplex Decision Module initialized
# âœ“ Processing 100 samples...
# âœ“ Complex mode: 15 times
# âœ“ Baseline mode: 85 times
# âœ“ Mode switches: 3
# âœ“ Alerts generated: 2
```

### PHASE 5: Export to ONNX (5 min)
```bash
# What: Export Mamba for production
# Time: 5 minutes
# Status: âœ“ Ready

python scripts/export_onnx.py

# Expected Output:
# âœ“ Exporting Mamba to ONNX...
# âœ“ Sample input shape: (1, 30, 14)
# âœ“ ONNX model created successfully
# âœ“ Saved: checkpoints/onnx_export/mamba_rul.onnx
# âœ“ Model validated
```

### PHASE 6: Generate Report (5 min)
```bash
# What: Create final evaluation report
# Time: 5 minutes
# Status: âœ“ Ready

python scripts/generate_report_fd001.py

# Expected Output:
# âœ“ Final Report Generation
# âœ“ Mamba RMSE: 20.40 cycles
# âœ“ LSTM RMSE: 38.24 cycles
# âœ“ Conformal Coverage: 91.2%
# âœ“ Simplex Mode Switches: 3
# âœ“ Total Alerts: 2
# âœ“ Report saved: outputs/final_safer_v3_report.json
```

---

## ðŸ“Š Expected Results Summary

After all phases complete, you should have:

```
âœ“ Models Trained
  - Mamba: RMSE 20.40 cycles (DAL E)
  - LSTM: RMSE 38.24 cycles (DAL C)
  - LPV-SINDy: 1673 sparse terms (DAL C)

âœ“ Predictions Calibrated
  - Coverage: 91.2% (target: 90%)
  - Interval Width: 38.55 cycles avg

âœ“ Safety Verified
  - Simplex: Functioning (mode switches 3x)
  - Alerts: Generated 2 critical

âœ“ Models Exported
  - PyTorch checkpoints: âœ“
  - ONNX format: âœ“
  - Deployment package: âœ“

âœ“ System Ready
  - Status: DEPLOYMENT READY
  - Latency: <20ms
  - Throughput: 50+ samples/sec
```

---

## ðŸŽ¯ One-Command Complete Execution

If all scripts are properly integrated, run:

```bash
# Option 1: Master script (if created)
python scripts/run_full_safer_pipeline.py

# Option 2: Sequential execution
bash << 'EOF'
python scripts/train_baseline_fd001.py --model mamba --epochs 20
python scripts/train_physics_fd001.py
python scripts/train_baseline_fd001.py --model lstm --epochs 20
python scripts/calibrate_fd001.py
python scripts/alert_and_simplex_fd001.py
python scripts/export_onnx.py
python scripts/generate_report_fd001.py
echo "âœ“ ALL PHASES COMPLETE"
EOF

# Option 3: Notebook execution
jupyter notebook train_mamba_kaggle.ipynb
# Then click "Run All Cells"
```

---

## â±ï¸ Timeline Summary

| Phase | Task | Time | Status |
|-------|------|------|--------|
| 1 | Data Prep | 5 min | â³ Quick |
| 2a | Train Mamba | 15 min | â³ Medium |
| 2b | Train LPV-SINDy | 10 min | â³ Medium |
| 2c | Train LSTM | 15 min | â³ Medium |
| 3 | Conformal Cal | 5 min | â³ Quick |
| 4 | Simplex Test | 5 min | â³ Quick |
| 5 | ONNX Export | 5 min | â³ Quick |
| 6 | Report Gen | 5 min | â³ Quick |
| **TOTAL** | **ALL** | **90 min** | âœ… Done |

---

## ðŸ” Verification Steps

After execution, verify everything worked:

```bash
# 1. Check model files exist
echo "Checking models..."
test -f checkpoints/mamba_rul.pt && echo "âœ“ Mamba" || echo "âœ— Mamba"
test -f checkpoints/lstm_baseline.pt && echo "âœ“ LSTM" || echo "âœ— LSTM"
test -f checkpoints/lpv_sindy_model.pt && echo "âœ“ LPV-SINDy" || echo "âœ— LPV-SINDy"
test -f checkpoints/onnx_export/mamba_rul.onnx && echo "âœ“ ONNX" || echo "âœ— ONNX"

# 2. Check outputs created
echo "Checking outputs..."
test -f outputs/final_safer_v3_report.json && echo "âœ“ Report" || echo "âœ— Report"
test -f outputs/X_train_seq.npy && echo "âœ“ Data" || echo "âœ— Data"

# 3. Check deployments
echo "Checking deployment..."
test -f deployment/models/deployment_config.json && echo "âœ“ Config" || echo "âœ— Config"
test -f deployment/inference/inference_example.py && echo "âœ“ Example" || echo "âœ— Example"

# 4. View final report
echo "Final Report:"
python -c "import json; r=json.load(open('outputs/final_safer_v3_report.json')); print(f\"Status: {r['status']}\"); print(f\"Mamba RMSE: {r['performance']['mamba']['rmse']:.2f}\"); print(f\"Coverage: {r['performance']['conformal']['coverage']:.2%}\")"
```

---

## ðŸ†˜ Troubleshooting

### Issue: Out of Memory
```bash
# Solution: Reduce batch size or sequence length
# Edit in training scripts:
batch_size = 16  # was 32
sequence_length = 15  # was 30
```

### Issue: Data Not Found
```bash
# Solution: Verify data directory
ls -la CMAPSSData/
# Should show: train_FD001.txt, test_FD001.txt, RUL_FD001.txt
```

### Issue: CUDA/GPU Error
```bash
# Solution: Force CPU execution
# Set before running:
export CUDA_VISIBLE_DEVICES=""
# Or edit scripts:
device = torch.device('cpu')
```

### Issue: Import Errors
```bash
# Solution: Reinstall package in dev mode
pip install -e .
# or
pip install -r requirements.txt --upgrade
```

---

## âœ¨ Success Indicators

You'll know it's working when you see:

âœ… Model training loss decreasing (epoch by epoch)  
âœ… RMSE values < 50 cycles for test set  
âœ… Conformal coverage near 90%  
âœ… Mode switches happening (not stuck in one mode)  
âœ… Alerts generating for low RUL values  
âœ… All checkpoint files created  
âœ… Final report generated with status "DEPLOYMENT READY"

---

## ðŸ“ž Quick Reference

| Want to... | Command |
|-----------|---------|
| Train everything | `python scripts/run_full_safer_pipeline.py` |
| Test one model | `python demo.py` |
| View results | `cat outputs/final_safer_v3_report.json` |
| Run tests | `pytest tests/test_integral_sindy.py -v` |
| Check performance | `python load_model.py` |
| Export for deployment | `python scripts/export_onnx.py` |

---

## ðŸŽ‰ Final Step

After all phases complete:

```bash
# View the masterpiece
cat outputs/final_safer_v3_report.json | python -m json.tool

# You should see:
# {
#   "status": "READY FOR DEPLOYMENT",
#   "performance": {
#     "mamba": { "rmse": 20.40, ... },
#     "conformal": { "coverage": 0.912, ... },
#     ...
#   }
# }
```

---

**Ready?** Start with: `python scripts/train_baseline_fd001.py --model mamba`

**Questions?** See `COMPLETE_END_TO_END_EXECUTION.md` for detailed explanations

